{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.metrics import classification_report, log_loss, accuracy_score\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:55:42.535126Z","iopub.execute_input":"2021-05-30T12:55:42.535490Z","iopub.status.idle":"2021-05-30T12:55:42.541005Z","shell.execute_reply.started":"2021-05-30T12:55:42.535458Z","shell.execute_reply":"2021-05-30T12:55:42.539839Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Load dataset","metadata":{}},{"cell_type":"code","source":"train_dir = '../input/major-data/MAJOR'\n\nName=[]\nfor file in os.listdir(train_dir):\n    Name+=[file]\nprint(Name)\nprint(len(Name))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:55:42.546044Z","iopub.execute_input":"2021-05-30T12:55:42.546327Z","iopub.status.idle":"2021-05-30T12:55:42.558330Z","shell.execute_reply.started":"2021-05-30T12:55:42.546303Z","shell.execute_reply":"2021-05-30T12:55:42.557293Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"['virabhadrasana i', 'padmasana', 'savasana', 'vajrasana', 'vrischikasana', 'vriksasana', 'utthita hasta padangustasana', 'virabhadrasana ii', 'ustrasana', 'dandasana', 'bakasana', 'tittibhasana', 'tolasana', 'salamba sarvangasana', 'prasarita padottanasana', 'uttanasana', 'tadasana', 'parivrtta janu sirsasana', 'parivrtta trikonasana', 'paripurna navasana', 'lolasana', 'ardha pincha mayurasana', 'simhasana', 'natarajasana', 'hanumanasana', 'durvasasana']\n26\n","output_type":"stream"}]},{"cell_type":"code","source":"N=[]\nfor i in range(len(Name)):\n    N+=[i]\n    \nnormal_mapping=dict(zip(Name,N)) \nreverse_mapping=dict(zip(N,Name)) ","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:55:42.559992Z","iopub.execute_input":"2021-05-30T12:55:42.560674Z","iopub.status.idle":"2021-05-30T12:55:42.565962Z","shell.execute_reply.started":"2021-05-30T12:55:42.560633Z","shell.execute_reply":"2021-05-30T12:55:42.564958Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def mapper(value):\n    return reverse_mapping[value]\n\ndataset=[]\ntestset=[]\ncount=0\nfor file in os.listdir(train_dir):\n    t=0\n    path=os.path.join(train_dir,file)\n    for im in os.listdir(path):\n        image=load_img(os.path.join(path,im), grayscale=False, color_mode='rgb', target_size=(40,40))\n        image=img_to_array(image)\n        image=image/255.0\n        if t < 70:\n            dataset+=[[image,count]]\n        else:\n            testset+=[[image,count]]\n        t+=1\n    count=count+1\n\ndata,labels0=zip(*dataset)\ntest,testlabels0=zip(*testset)\n\nlabels1=to_categorical(labels0)\nlabels=np.array(labels1)\n\ndata=np.array(data)\ntest=np.array(test)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:56:53.299280Z","iopub.execute_input":"2021-05-30T12:56:53.299599Z","iopub.status.idle":"2021-05-30T12:57:02.018907Z","shell.execute_reply.started":"2021-05-30T12:56:53.299571Z","shell.execute_reply":"2021-05-30T12:57:02.017900Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Taken very few images for  test 26 images","metadata":{}},{"cell_type":"code","source":"len(test)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:57:49.251675Z","iopub.execute_input":"2021-05-30T12:57:49.251997Z","iopub.status.idle":"2021-05-30T12:57:49.257043Z","shell.execute_reply.started":"2021-05-30T12:57:49.251967Z","shell.execute_reply":"2021-05-30T12:57:49.256170Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"26"},"metadata":{}}]},{"cell_type":"markdown","source":"# Split dataset","metadata":{}},{"cell_type":"code","source":"trainx,testx,trainy,testy=train_test_split(data,labels,test_size=0.2,random_state=44)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:57:02.020242Z","iopub.execute_input":"2021-05-30T12:57:02.020572Z","iopub.status.idle":"2021-05-30T12:57:02.036786Z","shell.execute_reply.started":"2021-05-30T12:57:02.020532Z","shell.execute_reply":"2021-05-30T12:57:02.035999Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Keras data pre processing","metadata":{}},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n                                horizontal_flip=True,\n                                vertical_flip=True,\n                                rotation_range=20,\n                                zoom_range=0.2,    \n                                width_shift_range=0.2,\n                                height_shift_range=0.2,\n                                shear_range=0.1,\n                                fill_mode=\"nearest\"\n                            )","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:55:59.920734Z","iopub.status.idle":"2021-05-30T12:55:59.921099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define model","metadata":{}},{"cell_type":"code","source":"pretrained_model = tf.keras.applications.DenseNet201(\n                                                        input_shape=(40,40,3),\n                                                        include_top=False,\n                                                        weights='imagenet',\n                                                        pooling='avg'\n                                                    )\npretrained_model.trainable = False\n\ninputs3 = pretrained_model.input\n\nx3 = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\noutputs3 = tf.keras.layers.Dense(26, activation='softmax')(x3)\n\nmodel = tf.keras.Model(inputs=inputs3, outputs=outputs3)\n\nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n\nhistory = model.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=100)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:55:59.922140Z","iopub.status.idle":"2021-05-30T12:55:59.922707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict ","metadata":{}},{"cell_type":"code","source":"y_pred=model.predict(testx)\npred=np.argmax(y_pred,axis=1)\nground = np.argmax(testy,axis=1)\nprint(classification_report(ground,pred))\n","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:55:59.923843Z","iopub.status.idle":"2021-05-30T12:55:59.924449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save Model","metadata":{}},{"cell_type":"code","source":"model.save(\"Datta_Yoga_Pose.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:55:59.925531Z","iopub.status.idle":"2021-05-30T12:55:59.926070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot History","metadata":{}},{"cell_type":"code","source":"get_acc = history.history['accuracy']\nvalue_acc = history.history['val_accuracy']\nget_loss = history.history['loss']\nvalidation_loss = history.history['val_loss']\n\nepochs = range(len(get_acc))\nplt.plot(epochs, get_acc, 'r', label='Accuracy of Training data')\nplt.plot(epochs, value_acc, 'b', label='Accuracy of Validation data')\nplt.title('Training vs validation accuracy')\nplt.legend(loc=0)\nplt.figure()\nplt.show()\n\nepochs = range(len(get_loss))\nplt.plot(epochs, get_loss, 'r', label='Loss of Training data')\nplt.plot(epochs, validation_loss, 'b', label='Loss of Validation data')\nplt.title('Training vs validation loss')\nplt.legend(loc=0)\nplt.figure()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:55:59.927252Z","iopub.status.idle":"2021-05-30T12:55:59.927798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Model using sample image","metadata":{}},{"cell_type":"code","source":"image=load_img(\"../input/major-data/MAJOR/lolasana/0-0.png\",target_size=(40,40))\n\nimage=img_to_array(image) \nimage=image/255.0\nprediction_image=np.array(image)\nprediction_image= np.expand_dims(image, axis=0)\n\nprediction=model.predict(prediction_image)\nvalue=np.argmax(prediction)\nmove_name=mapper(value)\nprint(\"Prediction is {}.\".format(move_name))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:55:59.928907Z","iopub.status.idle":"2021-05-30T12:55:59.929494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make prediction on test dataset","metadata":{}},{"cell_type":"code","source":"print(test.shape)\npred2=model.predict(test)\nprint(pred2.shape)\n\nPRED=[]\nfor item in pred2:\n    value2=np.argmax(item)      \n    PRED+=[value2]\n\nANS=testlabels0\n\naccuracy=accuracy_score(ANS,PRED)\nprint(accuracy)","metadata":{"_uuid":"015037cf-dd5a-4f24-a542-f238f313e994","_cell_guid":"3959f4e2-f9a0-4801-a5c6-fb52d433b860","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-05-30T12:55:59.930679Z","iopub.status.idle":"2021-05-30T12:55:59.931228Z"},"trusted":true},"execution_count":null,"outputs":[]}]}